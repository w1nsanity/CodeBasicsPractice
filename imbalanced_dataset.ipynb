{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70481fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec8d4ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age   \n",
       "0          1    15634602  Hargrave          619    France  Female   42  \\\n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember   \n",
       "0       2       0.00              1          1               1  \\\n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1143e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts   \n",
       "0          619    France  Female   42       2       0.00              1  \\\n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e69fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f999b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values_from_col(df):\n",
    "    for col in df:\n",
    "        print(f'{col} : {df[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1cfeb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geography : ['France' 'Spain' 'Germany']\n",
      "Gender : ['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "get_unique_values_from_col(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6ca7c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard   \n",
       "0             619  Female   42       2       0.00              1          1  \\\n",
       "1             608  Female   41       1   83807.86              1          0   \n",
       "2             502  Female   42       8  159660.80              3          1   \n",
       "3             699  Female   39       1       0.00              2          0   \n",
       "4             850  Female   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771    Male   39       5       0.00              2          1   \n",
       "9996          516    Male   35      10   57369.61              1          1   \n",
       "9997          709  Female   36       7       0.00              1          0   \n",
       "9998          772    Male   42       3   75075.31              2          1   \n",
       "9999          792  Female   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France   \n",
       "0                  1        101348.88       1              True  \\\n",
       "1                  1        112542.58       0             False   \n",
       "2                  0        113931.57       1              True   \n",
       "3                  0         93826.63       0              True   \n",
       "4                  1         79084.10       0             False   \n",
       "...              ...              ...     ...               ...   \n",
       "9995               0         96270.64       0              True   \n",
       "9996               1        101699.77       0              True   \n",
       "9997               1         42085.58       1              True   \n",
       "9998               0         92888.52       1             False   \n",
       "9999               0         38190.78       0              True   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "0                 False            False  \n",
       "1                 False             True  \n",
       "2                 False            False  \n",
       "3                 False            False  \n",
       "4                 False             True  \n",
       "...                 ...              ...  \n",
       "9995              False            False  \n",
       "9996              False            False  \n",
       "9997              False            False  \n",
       "9998               True            False  \n",
       "9999              False            False  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.get_dummies(df, columns=['Geography'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "742d430f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard   \n",
       "0             619  Female   42       2       0.00              1          1  \\\n",
       "1             608  Female   41       1   83807.86              1          0   \n",
       "2             502  Female   42       8  159660.80              3          1   \n",
       "3             699  Female   39       1       0.00              2          0   \n",
       "4             850  Female   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771    Male   39       5       0.00              2          1   \n",
       "9996          516    Male   35      10   57369.61              1          1   \n",
       "9997          709  Female   36       7       0.00              1          0   \n",
       "9998          772    Male   42       3   75075.31              2          1   \n",
       "9999          792  Female   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France   \n",
       "0                  1        101348.88       1                 1  \\\n",
       "1                  1        112542.58       0                 0   \n",
       "2                  0        113931.57       1                 1   \n",
       "3                  0         93826.63       0                 1   \n",
       "4                  1         79084.10       0                 0   \n",
       "...              ...              ...     ...               ...   \n",
       "9995               0         96270.64       0                 1   \n",
       "9996               1        101699.77       0                 1   \n",
       "9997               1         42085.58       1                 1   \n",
       "9998               0         92888.52       1                 0   \n",
       "9999               0         38190.78       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "0                     0                0  \n",
       "1                     0                1  \n",
       "2                     0                0  \n",
       "3                     0                0  \n",
       "4                     0                1  \n",
       "...                 ...              ...  \n",
       "9995                  0                0  \n",
       "9996                  0                0  \n",
       "9997                  0                0  \n",
       "9998                  1                0  \n",
       "9999                  0                0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_astype = ['Geography_France', 'Geography_Germany', 'Geography_Spain']\n",
    "df[cols_to_astype] = df[cols_to_astype].astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94f03ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard   \n",
       "0             619       1   42       2       0.00              1          1  \\\n",
       "1             608       1   41       1   83807.86              1          0   \n",
       "2             502       1   42       8  159660.80              3          1   \n",
       "3             699       1   39       1       0.00              2          0   \n",
       "4             850       1   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771       0   39       5       0.00              2          1   \n",
       "9996          516       0   35      10   57369.61              1          1   \n",
       "9997          709       1   36       7       0.00              1          0   \n",
       "9998          772       0   42       3   75075.31              2          1   \n",
       "9999          792       1   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France   \n",
       "0                  1        101348.88       1                 1  \\\n",
       "1                  1        112542.58       0                 0   \n",
       "2                  0        113931.57       1                 1   \n",
       "3                  0         93826.63       0                 1   \n",
       "4                  1         79084.10       0                 0   \n",
       "...              ...              ...     ...               ...   \n",
       "9995               0         96270.64       0                 1   \n",
       "9996               1        101699.77       0                 1   \n",
       "9997               1         42085.58       1                 1   \n",
       "9998               0         92888.52       1                 0   \n",
       "9999               0         38190.78       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "0                     0                0  \n",
       "1                     0                1  \n",
       "2                     0                0  \n",
       "3                     0                0  \n",
       "4                     0                1  \n",
       "...                 ...              ...  \n",
       "9995                  0                0  \n",
       "9996                  0                0  \n",
       "9997                  0                0  \n",
       "9998                  1                0  \n",
       "9999                  0                0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'] = df['Gender'].map({'Female': 1, 'Male': 0})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b111d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts   \n",
       "0           0.538       1  0.324324     0.2  0.000000       0.000000  \\\n",
       "1           0.516       1  0.310811     0.1  0.334031       0.000000   \n",
       "2           0.304       1  0.324324     0.8  0.636357       0.666667   \n",
       "3           0.698       1  0.283784     0.1  0.000000       0.333333   \n",
       "4           1.000       1  0.337838     0.2  0.500246       0.000000   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9995        0.842       0  0.283784     0.5  0.000000       0.333333   \n",
       "9996        0.332       0  0.229730     1.0  0.228657       0.000000   \n",
       "9997        0.718       1  0.243243     0.7  0.000000       0.000000   \n",
       "9998        0.844       0  0.324324     0.3  0.299226       0.333333   \n",
       "9999        0.884       1  0.135135     0.4  0.518708       0.000000   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_France   \n",
       "0             1               1         0.506735       1                 1  \\\n",
       "1             0               1         0.562709       0                 0   \n",
       "2             1               0         0.569654       1                 1   \n",
       "3             0               0         0.469120       0                 1   \n",
       "4             1               1         0.395400       0                 0   \n",
       "...         ...             ...              ...     ...               ...   \n",
       "9995          1               0         0.481341       0                 1   \n",
       "9996          1               1         0.508490       0                 1   \n",
       "9997          0               1         0.210390       1                 1   \n",
       "9998          1               0         0.464429       1                 0   \n",
       "9999          1               0         0.190914       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "0                     0                0  \n",
       "1                     0                1  \n",
       "2                     0                0  \n",
       "3                     0                0  \n",
       "4                     0                1  \n",
       "...                 ...              ...  \n",
       "9995                  0                0  \n",
       "9996                  0                0  \n",
       "9997                  0                0  \n",
       "9998                  1                0  \n",
       "9999                  0                0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "cols_to_scale = ['CreditScore','Age','Tenure', 'Balance','NumOfProducts','EstimatedSalary']\n",
    "\n",
    "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f26df17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.601058</td>\n",
       "      <td>0.454300</td>\n",
       "      <td>0.282727</td>\n",
       "      <td>0.501280</td>\n",
       "      <td>0.304848</td>\n",
       "      <td>0.176733</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>0.500441</td>\n",
       "      <td>0.203700</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.247700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.193307</td>\n",
       "      <td>0.497932</td>\n",
       "      <td>0.141727</td>\n",
       "      <td>0.289217</td>\n",
       "      <td>0.248696</td>\n",
       "      <td>0.193885</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>0.287580</td>\n",
       "      <td>0.402769</td>\n",
       "      <td>0.500023</td>\n",
       "      <td>0.433553</td>\n",
       "      <td>0.431698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.468000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.387402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.736000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.508749</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.746955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore        Gender           Age        Tenure       Balance   \n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000  \\\n",
       "mean       0.601058      0.454300      0.282727      0.501280      0.304848   \n",
       "std        0.193307      0.497932      0.141727      0.289217      0.248696   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.468000      0.000000      0.189189      0.300000      0.000000   \n",
       "50%        0.604000      0.000000      0.256757      0.500000      0.387402   \n",
       "75%        0.736000      1.000000      0.351351      0.700000      0.508749   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       NumOfProducts    HasCrCard  IsActiveMember  EstimatedSalary   \n",
       "count   10000.000000  10000.00000    10000.000000     10000.000000  \\\n",
       "mean        0.176733      0.70550        0.515100         0.500441   \n",
       "std         0.193885      0.45584        0.499797         0.287580   \n",
       "min         0.000000      0.00000        0.000000         0.000000   \n",
       "25%         0.000000      0.00000        0.000000         0.254977   \n",
       "50%         0.000000      1.00000        1.000000         0.500960   \n",
       "75%         0.333333      1.00000        1.000000         0.746955   \n",
       "max         1.000000      1.00000        1.000000         1.000000   \n",
       "\n",
       "             Exited  Geography_France  Geography_Germany  Geography_Spain  \n",
       "count  10000.000000      10000.000000       10000.000000     10000.000000  \n",
       "mean       0.203700          0.501400           0.250900         0.247700  \n",
       "std        0.402769          0.500023           0.433553         0.431698  \n",
       "min        0.000000          0.000000           0.000000         0.000000  \n",
       "25%        0.000000          0.000000           0.000000         0.000000  \n",
       "50%        0.000000          1.000000           0.000000         0.000000  \n",
       "75%        0.000000          1.000000           1.000000         0.000000  \n",
       "max        1.000000          1.000000           1.000000         1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8da5cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts   \n",
       "0           0.538       1  0.324324     0.2  0.000000       0.000000  \\\n",
       "1           0.516       1  0.310811     0.1  0.334031       0.000000   \n",
       "2           0.304       1  0.324324     0.8  0.636357       0.666667   \n",
       "3           0.698       1  0.283784     0.1  0.000000       0.333333   \n",
       "4           1.000       1  0.337838     0.2  0.500246       0.000000   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9995        0.842       0  0.283784     0.5  0.000000       0.333333   \n",
       "9996        0.332       0  0.229730     1.0  0.228657       0.000000   \n",
       "9997        0.718       1  0.243243     0.7  0.000000       0.000000   \n",
       "9998        0.844       0  0.324324     0.3  0.299226       0.333333   \n",
       "9999        0.884       1  0.135135     0.4  0.518708       0.000000   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_France   \n",
       "0             1               1         0.506735                 1  \\\n",
       "1             0               1         0.562709                 0   \n",
       "2             1               0         0.569654                 1   \n",
       "3             0               0         0.469120                 1   \n",
       "4             1               1         0.395400                 0   \n",
       "...         ...             ...              ...               ...   \n",
       "9995          1               0         0.481341                 1   \n",
       "9996          1               1         0.508490                 1   \n",
       "9997          0               1         0.210390                 1   \n",
       "9998          1               0         0.464429                 0   \n",
       "9999          1               0         0.190914                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "0                     0                0  \n",
       "1                     0                1  \n",
       "2                     0                0  \n",
       "3                     0                0  \n",
       "4                     0                1  \n",
       "...                 ...              ...  \n",
       "9995                  0                0  \n",
       "9996                  0                0  \n",
       "9997                  0                0  \n",
       "9998                  1                0  \n",
       "9999                  0                0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Exited', axis=1)\n",
    "y = df.Exited\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baef9a00",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [0.538 0.516 0.304 0.698 1.    0.59  0.944 0.052 0.302 0.668 0.356 0.294\n",
      " 0.252 0.398 0.57  0.532 0.606 0.474 0.752 0.764 0.572 0.32  0.638 0.992\n",
      " 0.454 0.812 0.442 0.448 0.122 0.482 0.366 0.406 0.34  0.744 0.25  0.28\n",
      " 0.908 0.464 0.244 0.23  0.412 0.968 0.62  0.852 0.958 0.574 0.4   0.696\n",
      " 0.47  0.876 0.61  0.502 0.612 0.75  0.322 0.528 0.784 0.674 0.41  0.506\n",
      " 0.802 0.462 0.77  0.622 0.65  0.776 0.926 0.614 0.508 0.338 0.628 0.656\n",
      " 0.814 0.132 0.63  0.854 0.386 0.312 0.286 0.604 0.8   0.758 0.592 0.594\n",
      " 0.916 0.348 0.838 0.76  0.33  0.846 0.928 0.72  0.126 0.546 0.64  0.544\n",
      " 0.87  0.51  0.258 0.67  0.376 0.424 0.742 0.556 0.636 0.956 0.648 0.55\n",
      " 0.164 0.84  0.816 0.89  0.672 0.878 0.478 0.222 0.468 0.458 0.626 0.664\n",
      " 0.886 0.682 0.27  0.6   0.808 0.37  0.732 0.378 0.712 0.472 0.562 0.734\n",
      " 0.9   0.666 0.708 0.53  0.634 0.268 0.26  0.456 0.324 0.512 0.494 0.856\n",
      " 0.328 0.35  0.73  0.46  0.914 0.342 0.818 0.332 0.722 0.536 0.586 0.642\n",
      " 0.678 0.54  0.652 0.444 0.69  0.484 0.434 0.688 0.394 0.488 0.646 0.52\n",
      " 0.834 0.826 0.724 0.706 0.624 0.618 0.346 0.844 0.39  0.568 0.778 0.842\n",
      " 0.662 0.388 0.692 0.832 0.754 0.686 0.414 0.362 0.296 0.602 0.882 0.766\n",
      " 0.922 0.714 0.728 0.864 0.85  0.898 0.504 0.788 0.476 0.794 0.466 0.554\n",
      " 0.762 0.558 0.176 0.584 0.912 0.248 0.418 0.158 0.66  0.798 0.768 0.588\n",
      " 0.552 0.598 0.91  0.736 0.98  0.56  0.608 0.824 0.436 0.526 0.344 0.774\n",
      " 0.596 0.186 0.58  0.38  0.22  0.486 0.902 0.522 0.904 0.79  0.266 0.68\n",
      " 0.284 0.718 0.71  0.42  0.804 0.702 0.374 0.274 0.492 0.704 0.272 0.748\n",
      " 0.396 0.228 0.88  0.368 0.796 0.288 0.48  0.236 0.318 0.936 0.932 0.372\n",
      " 0.806 0.848 0.542 0.438 0.616 0.896 0.582 0.384 0.684 0.578 0.83  0.44\n",
      " 0.576 0.498 0.564 0.858 0.354 0.428 0.966 0.308 0.984 0.316 0.134 0.496\n",
      " 0.782 0.514 0.822 0.996 0.392 0.178 0.81  0.82  0.352 0.726 0.7   0.632\n",
      " 0.432 0.29  0.676 0.524 0.254 0.154 0.978 0.938 0.74  0.218 0.306 0.548\n",
      " 0.358 0.426 0.264 0.892 0.19  0.792 0.872 0.408 0.644 0.874 0.298 0.988\n",
      " 0.2   0.93  0.976 0.906 0.772 0.566 0.5   0.658 0.334 0.884 0.786 0.276\n",
      " 0.142 0.982 0.716 0.314 0.31  0.212 0.17  0.422 0.336 0.43  0.756 0.868\n",
      " 0.404 0.518 0.828 0.694 0.746 0.402 0.188 0.738 0.292 0.382 0.96  0.924\n",
      " 0.654 0.14  0.49  0.534 0.918 0.3   0.952 0.168 0.326 0.256 0.894 0.026\n",
      " 0.098 0.226 0.86  0.204 0.45  0.974 0.888 0.948 0.156 0.946 0.862 0.998\n",
      " 0.278 0.162 0.214 0.836 0.962 0.018 0.94  0.446 0.452 0.416 0.934 0.198\n",
      " 0.18  0.13  0.942 0.36  0.    0.192 0.15  0.78  0.262 0.866 0.016 0.99\n",
      " 0.202 0.216 0.238 0.146 0.108 0.972 0.246 0.97  0.232 0.282 0.002 0.954\n",
      " 0.986 0.03  0.364 0.128 0.206 0.242 0.102 0.92  0.964 0.24  0.194 0.144\n",
      " 0.95  0.16  0.172 0.152 0.116 0.994 0.136 0.174 0.12  0.208 0.114 0.21\n",
      " 0.224 0.072 0.11  0.066 0.09  0.234 0.166 0.184 0.148 0.196 0.182 0.034\n",
      " 0.124 0.064 0.046 0.138]\n",
      "Gender : [1 0]\n",
      "Age : [0.32432432 0.31081081 0.28378378 0.33783784 0.35135135 0.43243243\n",
      " 0.14864865 0.12162162 0.17567568 0.08108108 0.21621622 0.09459459\n",
      " 0.22972973 0.36486486 0.54054054 0.18918919 0.27027027 0.37837838\n",
      " 0.24324324 0.2027027  0.2972973  0.44594595 0.58108108 0.41891892\n",
      " 0.25675676 0.01351351 0.64864865 0.51351351 0.10810811 0.04054054\n",
      " 0.5        0.77027027 0.05405405 0.16216216 0.13513514 0.63513514\n",
      " 0.40540541 0.45945946 0.52702703 0.74324324 0.39189189 0.48648649\n",
      " 0.72972973 0.02702703 0.66216216 0.82432432 0.59459459 0.47297297\n",
      " 0.83783784 0.55405405 0.67567568 0.06756757 0.56756757 0.7027027\n",
      " 0.60810811 0.62162162 0.         0.86486486 0.68918919 0.75675676\n",
      " 0.71621622 0.78378378 0.7972973  0.94594595 0.90540541 0.89189189\n",
      " 0.81081081 0.85135135 1.         0.87837838]\n",
      "Tenure : [0.2 0.1 0.8 0.7 0.4 0.6 0.3 1.  0.5 0.9 0. ]\n",
      "Balance : [0.         0.33403148 0.63635718 ... 0.22865702 0.29922631 0.51870777]\n",
      "NumOfProducts : [0.         0.66666667 0.33333333 1.        ]\n",
      "HasCrCard : [1 0]\n",
      "IsActiveMember : [1 0]\n",
      "EstimatedSalary : [0.50673489 0.56270874 0.56965435 ... 0.21039009 0.46442905 0.19091423]\n",
      "Exited : [1 0]\n",
      "Geography_France : [1 0]\n",
      "Geography_Germany : [0 1]\n",
      "Geography_Spain : [0 1]\n"
     ]
    }
   ],
   "source": [
    "get_unique_values_from_col(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e605dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3d6ddab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 12), (8000,), (2000, 12), (2000,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f55381ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    6370\n",
       "1    1630\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8f4e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79173\\Desktop\\CodeBasics\\CodeBas\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_addons import losses\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix , classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7d81414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(12, input_dim=12, activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(6, activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    if weights == -1:\n",
    "        model.fit(X_train, y_train, epochs=100)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=100, class_weight = weights)\n",
    "    \n",
    "    print(model.evaluate(X_test, y_test))\n",
    "    \n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "    \n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "    print(model.get_weights())\n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0ce97b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7896\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7952\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7962\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7964\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7960\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7966\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7972\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7986\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8011\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.8096\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8139\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.8136\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4259 - accuracy: 0.8149\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4241 - accuracy: 0.8161\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.8200\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8238\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8215\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8239\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4157 - accuracy: 0.8225\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8246\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8245\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8260\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8239\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4063 - accuracy: 0.8290\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4066 - accuracy: 0.8269\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4077 - accuracy: 0.8257\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8273\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.8266\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8284\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4075 - accuracy: 0.8288\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4056 - accuracy: 0.8260\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4012 - accuracy: 0.8288\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8316\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.8266\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8246\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4011 - accuracy: 0.8289\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.8282\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3963 - accuracy: 0.8313\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4037 - accuracy: 0.8267\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8317\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3995 - accuracy: 0.8274\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4009 - accuracy: 0.8298\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3972 - accuracy: 0.8267\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4001 - accuracy: 0.8265\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3963 - accuracy: 0.8311\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3942 - accuracy: 0.8294\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8295\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8330\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3984 - accuracy: 0.8266\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3981 - accuracy: 0.8331\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3963 - accuracy: 0.8311\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3976 - accuracy: 0.8306\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8328\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3986 - accuracy: 0.8282\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8328\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8320\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8292\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.8263\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8317\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3928 - accuracy: 0.8321\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3946 - accuracy: 0.8299\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.8347\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3924 - accuracy: 0.8296\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.8334\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8301\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.8329\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.8306\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8353\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3924 - accuracy: 0.8310\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3840 - accuracy: 0.8349\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8336\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.8316\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3865 - accuracy: 0.8357\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3902 - accuracy: 0.8342\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8313\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8303\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3865 - accuracy: 0.8355\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8342\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.8299\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8320\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.8328\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8331\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8386\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3861 - accuracy: 0.8359\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8354\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3834 - accuracy: 0.8374\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8317\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8382\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8330\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3824 - accuracy: 0.8331\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3835 - accuracy: 0.8390\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3774 - accuracy: 0.8375\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8405\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8376\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8376\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 0.8407\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8386\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3791 - accuracy: 0.8371\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8381\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3803 - accuracy: 0.8389\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8630\n",
      "[0.34174343943595886, 0.8629999756813049]\n",
      "63/63 [==============================] - 0s 966us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      1593\n",
      "           1       0.79      0.44      0.57       407\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.83      0.71      0.74      2000\n",
      "weighted avg       0.86      0.86      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a34b783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_preds)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6140dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class count\n",
    "count_class_0, count_class_1 = df.Exited.value_counts()\n",
    "\n",
    "# divide by class\n",
    "df_class_0 = df[df.Exited == 0]\n",
    "df_class_1 = df[df.Exited == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a57a312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7963, 13), (2037, 13))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_0.shape, df_class_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a7b8043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>0.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.339691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.34041</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.554098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts   \n",
       "1867         0.73       1  0.202703     0.3  0.339691            0.0  \\\n",
       "1662         0.69       0  0.297297     0.7  0.554098            0.0   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_France   \n",
       "1867          1               1          0.34041       0                 1  \\\n",
       "1662          0               1          0.96695       0                 0   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "1867                  0                0  \n",
       "1662                  1                0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_0.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "576e60dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7538</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>0.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.411381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.860888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.378</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.508611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>0.772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258492</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.956</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.856918</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4416</th>\n",
       "      <td>0.242</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.657444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.952692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7359</th>\n",
       "      <td>0.632</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.478941</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>0.334</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8192</th>\n",
       "      <td>0.478</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.456103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134734</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2037 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts   \n",
       "7538        0.502       0  0.135135     0.6  0.000000       0.333333  \\\n",
       "2534        0.734       1  0.229730     0.5  0.411381       0.000000   \n",
       "153         0.378       0  0.256757     0.2  0.508611       0.000000   \n",
       "7597        0.772       0  0.148649     0.4  0.000000       0.333333   \n",
       "5001        0.808       0  0.229730     0.4  0.000000       0.333333   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "128         0.956       1  0.310811     0.7  0.000000       0.333333   \n",
       "4416        0.242       0  0.324324     0.3  0.657444       0.000000   \n",
       "7359        0.632       0  0.243243     0.4  0.478941       0.333333   \n",
       "4813        0.334       0  0.283784     0.3  0.000000       0.333333   \n",
       "8192        0.478       0  0.243243     0.8  0.456103       0.000000   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_France   \n",
       "7538          1               0         0.073275       0                 0  \\\n",
       "2534          1               0         0.860888       0                 0   \n",
       "153           1               0         0.493220       0                 1   \n",
       "7597          0               0         0.258492       0                 1   \n",
       "5001          1               1         0.048239       0                 0   \n",
       "...         ...             ...              ...     ...               ...   \n",
       "128           1               0         0.856918       0                 1   \n",
       "4416          1               0         0.952692       0                 1   \n",
       "7359          1               0         0.168466       0                 1   \n",
       "4813          0               1         0.062276       0                 0   \n",
       "8192          1               0         0.134734       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "7538                  0                1  \n",
       "2534                  1                0  \n",
       "153                   0                0  \n",
       "7597                  0                0  \n",
       "5001                  0                1  \n",
       "...                 ...              ...  \n",
       "128                   0                0  \n",
       "4416                  0                0  \n",
       "7359                  0                0  \n",
       "4813                  0                1  \n",
       "8192                  0                0  \n",
       "\n",
       "[2037 rows x 13 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_0_under = df_class_0.sample(df_class_1.shape[0], replace=True)\n",
    "df_class_0_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d4cb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8e8af1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7538</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>0.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.411381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.860888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.378</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.508611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>0.772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258492</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>0.296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.605982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>0.610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.546617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575729</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>0.494</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472973</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.352259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.346899</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4074 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts   \n",
       "7538        0.502       0  0.135135     0.6  0.000000       0.333333  \\\n",
       "2534        0.734       1  0.229730     0.5  0.411381       0.000000   \n",
       "153         0.378       0  0.256757     0.2  0.508611       0.000000   \n",
       "7597        0.772       0  0.148649     0.4  0.000000       0.333333   \n",
       "5001        0.808       0  0.229730     0.4  0.000000       0.333333   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9981        0.296       0  0.324324     0.3  0.605982       0.000000   \n",
       "9982        0.610       1  0.378378     0.7  0.546617       0.000000   \n",
       "9991        0.494       1  0.472973     0.4  0.352259       0.000000   \n",
       "9997        0.718       1  0.243243     0.7  0.000000       0.000000   \n",
       "9998        0.844       0  0.324324     0.3  0.299226       0.333333   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_France   \n",
       "7538          1               0         0.073275       0                 0  \\\n",
       "2534          1               0         0.860888       0                 0   \n",
       "153           1               0         0.493220       0                 1   \n",
       "7597          0               0         0.258492       0                 1   \n",
       "5001          1               1         0.048239       0                 0   \n",
       "...         ...             ...              ...     ...               ...   \n",
       "9981          1               1         0.267193       1                 0   \n",
       "9982          1               0         0.575729       1                 0   \n",
       "9991          1               0         0.346899       1                 1   \n",
       "9997          0               1         0.210390       1                 1   \n",
       "9998          1               0         0.464429       1                 0   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "7538                  0                1  \n",
       "2534                  1                0  \n",
       "153                   0                0  \n",
       "7597                  0                0  \n",
       "5001                  0                1  \n",
       "...                 ...              ...  \n",
       "9981                  1                0  \n",
       "9982                  1                0  \n",
       "9991                  0                0  \n",
       "9997                  0                0  \n",
       "9998                  1                0  \n",
       "\n",
       "[4074 rows x 13 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a8b5cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "Exited\n",
      "0    2037\n",
      "1    2037\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Random under-sampling:')\n",
    "print(df_test_under.Exited.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eaaef222",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_under.drop('Exited',axis='columns')\n",
    "y = df_test_under['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "288e1e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16456933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "1    1630\n",
       "0    1629\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b356fb10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.7031 - accuracy: 0.5532\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.5640\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.5910\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.5937\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6103\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6214\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6220\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6312\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.6250\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 0.6471\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6356 - accuracy: 0.6450\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.6481\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6542\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6560\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6502\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6714\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6631\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6701\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6711\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.6852\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6018 - accuracy: 0.6784\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6907\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6907\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7039\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.7011\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.6898\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.7103\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.6984\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7110\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7159\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7079\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7116\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7284\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7214\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5593 - accuracy: 0.7278\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5557 - accuracy: 0.7205\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.7269\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5500 - accuracy: 0.7205\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.7358\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.7370\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7364\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5330 - accuracy: 0.7456\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5367 - accuracy: 0.7395\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5324 - accuracy: 0.7432\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5284 - accuracy: 0.7435\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5250 - accuracy: 0.7462\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5317 - accuracy: 0.7496\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.7472\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5268 - accuracy: 0.7472\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5249 - accuracy: 0.7542\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.7545\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5250 - accuracy: 0.7450\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7573\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7469\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.7524\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5252 - accuracy: 0.7530\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7472\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7573\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7530\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.7496\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5147 - accuracy: 0.7570\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7564\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.7551\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7551\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7518\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7521\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7597\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.7564\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7570\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7702\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7582\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.7573\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.7533\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.7561\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7591\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7631\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7536\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7671\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7613\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.7631\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7548\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7634\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.7610\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.7533\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7637\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7533\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7656\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7671\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7619\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.7656\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.7564\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7705\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7554\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7668\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7607\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.7653\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.7665\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7561\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7600\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7696\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.7620\n",
      "[0.49306344985961914, 0.7619631886482239]\n",
      "26/26 [==============================] - 0s 851us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77       408\n",
      "           1       0.77      0.74      0.76       407\n",
      "\n",
      "    accuracy                           0.76       815\n",
      "   macro avg       0.76      0.76      0.76       815\n",
      "weighted avg       0.76      0.76      0.76       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "de55e779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "Exited\n",
      "0    7963\n",
      "1    7963\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Oversample 1-class and concat the DataFrames of both classes\n",
    "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.Exited.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3799fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_over.drop('Exited',axis='columns')\n",
    "y = df_test_over['Exited']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f25e8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    6370\n",
       "1    6370\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3791483",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5457\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6498 - accuracy: 0.6305\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.6286 - accuracy: 0.6601\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.6114 - accuracy: 0.6792\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5881 - accuracy: 0.6969\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5695 - accuracy: 0.7148\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5622 - accuracy: 0.7183\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5480 - accuracy: 0.7309\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7355\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7349\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7407\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5257 - accuracy: 0.7447\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5262 - accuracy: 0.7428\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5193 - accuracy: 0.7470\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5175 - accuracy: 0.7451\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5185 - accuracy: 0.7458\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5121 - accuracy: 0.7501\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5095 - accuracy: 0.7505\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5112 - accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7507\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5048 - accuracy: 0.7523\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.7529\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5070 - accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5008 - accuracy: 0.7554\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5023 - accuracy: 0.7550\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5026 - accuracy: 0.7579\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4990 - accuracy: 0.7531\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5071 - accuracy: 0.7521\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5019 - accuracy: 0.7542\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5031 - accuracy: 0.7524\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5003 - accuracy: 0.7579\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5004 - accuracy: 0.7524\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5013 - accuracy: 0.7516\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4985 - accuracy: 0.7567\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4995 - accuracy: 0.7572\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4974 - accuracy: 0.7597\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5003 - accuracy: 0.7575\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5004 - accuracy: 0.7572\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4982 - accuracy: 0.7562\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4953 - accuracy: 0.7607\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4976 - accuracy: 0.7571\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4987 - accuracy: 0.7543\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4941 - accuracy: 0.7616\n",
      "Epoch 44/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4975 - accuracy: 0.7588\n",
      "Epoch 45/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4960 - accuracy: 0.7598\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4993 - accuracy: 0.7576\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4999 - accuracy: 0.7549\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4952 - accuracy: 0.7623\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4922 - accuracy: 0.7637\n",
      "Epoch 50/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4932 - accuracy: 0.7619\n",
      "Epoch 51/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4912 - accuracy: 0.7593\n",
      "Epoch 52/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4926 - accuracy: 0.7622\n",
      "Epoch 53/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4938 - accuracy: 0.7584\n",
      "Epoch 54/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7596\n",
      "Epoch 55/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4918 - accuracy: 0.7617\n",
      "Epoch 56/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.7608\n",
      "Epoch 57/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4900 - accuracy: 0.7657\n",
      "Epoch 58/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7641\n",
      "Epoch 59/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7655\n",
      "Epoch 60/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7644\n",
      "Epoch 61/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4886 - accuracy: 0.7640\n",
      "Epoch 62/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4887 - accuracy: 0.7596\n",
      "Epoch 63/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4884 - accuracy: 0.7630\n",
      "Epoch 64/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4893 - accuracy: 0.7637\n",
      "Epoch 65/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4910 - accuracy: 0.7683\n",
      "Epoch 66/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4909 - accuracy: 0.7644\n",
      "Epoch 67/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4890 - accuracy: 0.7633\n",
      "Epoch 68/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4907 - accuracy: 0.7575\n",
      "Epoch 69/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4864 - accuracy: 0.7655\n",
      "Epoch 70/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4894 - accuracy: 0.7648\n",
      "Epoch 71/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4900 - accuracy: 0.7645\n",
      "Epoch 72/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4871 - accuracy: 0.7675\n",
      "Epoch 73/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4877 - accuracy: 0.7635\n",
      "Epoch 74/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4824 - accuracy: 0.7661\n",
      "Epoch 75/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4888 - accuracy: 0.7642\n",
      "Epoch 76/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4862 - accuracy: 0.7675\n",
      "Epoch 77/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4856 - accuracy: 0.7655\n",
      "Epoch 78/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4872 - accuracy: 0.7696\n",
      "Epoch 79/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4831 - accuracy: 0.7689\n",
      "Epoch 80/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4861 - accuracy: 0.7642\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4858 - accuracy: 0.7664\n",
      "Epoch 82/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4846 - accuracy: 0.7687\n",
      "Epoch 83/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4863 - accuracy: 0.7637\n",
      "Epoch 84/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4884 - accuracy: 0.7657\n",
      "Epoch 85/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4892 - accuracy: 0.7655\n",
      "Epoch 86/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4812 - accuracy: 0.7653\n",
      "Epoch 87/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4861 - accuracy: 0.7677\n",
      "Epoch 88/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4904 - accuracy: 0.7662\n",
      "Epoch 89/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4879 - accuracy: 0.7697\n",
      "Epoch 90/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.7682\n",
      "Epoch 91/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4832 - accuracy: 0.7644\n",
      "Epoch 92/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4821 - accuracy: 0.7675\n",
      "Epoch 93/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.7673\n",
      "Epoch 94/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.7648\n",
      "Epoch 95/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4831 - accuracy: 0.7711\n",
      "Epoch 96/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.7674\n",
      "Epoch 97/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.7711\n",
      "Epoch 98/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4870 - accuracy: 0.7650\n",
      "Epoch 99/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4817 - accuracy: 0.7732\n",
      "Epoch 100/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4804 - accuracy: 0.7703\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7844\n",
      "[0.4488796591758728, 0.7843691110610962]\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79      1593\n",
      "           1       0.81      0.74      0.77      1593\n",
      "\n",
      "    accuracy                           0.78      3186\n",
      "   macro avg       0.79      0.78      0.78      3186\n",
      "weighted avg       0.79      0.78      0.78      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b55ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited',axis='columns')\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "09f412bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 12), (10000,))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ee9a7084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "1    7963\n",
       "0    7963\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5c39641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a282866f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    1593\n",
       "1    1593\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of classes in training Data\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6e6d79c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    6370\n",
       "1    6370\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "271b98fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "399/399 [==============================] - 2s 2ms/step - loss: 0.6895 - accuracy: 0.5582\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6559 - accuracy: 0.6265\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6247 - accuracy: 0.6677\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.6958\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5794 - accuracy: 0.7040\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5660 - accuracy: 0.7159\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5545 - accuracy: 0.7186\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5463 - accuracy: 0.7275\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7314\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7358\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5274 - accuracy: 0.7378\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5261 - accuracy: 0.7405\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5216 - accuracy: 0.7422\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5145 - accuracy: 0.7479\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5118 - accuracy: 0.7464\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5103 - accuracy: 0.7505\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.7440\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5097 - accuracy: 0.7487\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5080 - accuracy: 0.7495\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5051 - accuracy: 0.7510\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5053 - accuracy: 0.7510\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5037 - accuracy: 0.7502\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5023 - accuracy: 0.7560\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5009 - accuracy: 0.7541\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5028 - accuracy: 0.7550\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5040 - accuracy: 0.7549\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4978 - accuracy: 0.7554\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7556\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5016 - accuracy: 0.7558\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5012 - accuracy: 0.7560\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5023 - accuracy: 0.7518\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4976 - accuracy: 0.7561\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5006 - accuracy: 0.7533\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4963 - accuracy: 0.7575\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4974 - accuracy: 0.7541\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4972 - accuracy: 0.7587\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5039 - accuracy: 0.7576\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4990 - accuracy: 0.7580\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4962 - accuracy: 0.7600\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4944 - accuracy: 0.7619\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4969 - accuracy: 0.7589\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4959 - accuracy: 0.7619\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4954 - accuracy: 0.7611\n",
      "Epoch 44/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5025 - accuracy: 0.7562\n",
      "Epoch 45/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4938 - accuracy: 0.7652\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4913 - accuracy: 0.7626\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4927 - accuracy: 0.7600\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4977 - accuracy: 0.7589\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4946 - accuracy: 0.7572\n",
      "Epoch 50/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4950 - accuracy: 0.7619\n",
      "Epoch 51/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4967 - accuracy: 0.7625\n",
      "Epoch 52/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4934 - accuracy: 0.7596\n",
      "Epoch 53/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4921 - accuracy: 0.7598\n",
      "Epoch 54/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4942 - accuracy: 0.7584\n",
      "Epoch 55/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4961 - accuracy: 0.7584\n",
      "Epoch 56/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4968 - accuracy: 0.7610\n",
      "Epoch 57/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4958 - accuracy: 0.7591\n",
      "Epoch 58/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4970 - accuracy: 0.7644\n",
      "Epoch 59/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4933 - accuracy: 0.7590\n",
      "Epoch 60/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4948 - accuracy: 0.7615\n",
      "Epoch 61/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4911 - accuracy: 0.7600\n",
      "Epoch 62/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4946 - accuracy: 0.7637\n",
      "Epoch 63/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4937 - accuracy: 0.7613\n",
      "Epoch 64/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4950 - accuracy: 0.7632\n",
      "Epoch 65/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4908 - accuracy: 0.7651\n",
      "Epoch 66/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4934 - accuracy: 0.7623\n",
      "Epoch 67/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4912 - accuracy: 0.7632\n",
      "Epoch 68/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4919 - accuracy: 0.7622\n",
      "Epoch 69/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4920 - accuracy: 0.7611\n",
      "Epoch 70/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4959 - accuracy: 0.7604\n",
      "Epoch 71/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4914 - accuracy: 0.7610\n",
      "Epoch 72/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4923 - accuracy: 0.7573\n",
      "Epoch 73/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4953 - accuracy: 0.7595\n",
      "Epoch 74/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4966 - accuracy: 0.7571\n",
      "Epoch 75/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4922 - accuracy: 0.7597\n",
      "Epoch 76/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4933 - accuracy: 0.7626\n",
      "Epoch 77/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4907 - accuracy: 0.7613\n",
      "Epoch 78/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4946 - accuracy: 0.7615\n",
      "Epoch 79/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4943 - accuracy: 0.7604\n",
      "Epoch 80/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4948 - accuracy: 0.7673\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4894 - accuracy: 0.7655\n",
      "Epoch 82/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4920 - accuracy: 0.7622\n",
      "Epoch 83/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4940 - accuracy: 0.7593\n",
      "Epoch 84/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4892 - accuracy: 0.7610\n",
      "Epoch 85/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4962 - accuracy: 0.7542\n",
      "Epoch 86/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4900 - accuracy: 0.7663\n",
      "Epoch 87/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4912 - accuracy: 0.7609\n",
      "Epoch 88/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4922 - accuracy: 0.7652\n",
      "Epoch 89/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4921 - accuracy: 0.7608\n",
      "Epoch 90/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4904 - accuracy: 0.7648\n",
      "Epoch 91/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4936 - accuracy: 0.7591\n",
      "Epoch 92/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4905 - accuracy: 0.7638\n",
      "Epoch 93/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4889 - accuracy: 0.7649\n",
      "Epoch 94/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4886 - accuracy: 0.7641\n",
      "Epoch 95/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4906 - accuracy: 0.7646\n",
      "Epoch 96/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4920 - accuracy: 0.7656\n",
      "Epoch 97/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4902 - accuracy: 0.7622\n",
      "Epoch 98/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4936 - accuracy: 0.7636\n",
      "Epoch 99/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4938 - accuracy: 0.7599\n",
      "Epoch 100/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4911 - accuracy: 0.7593\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7837\n",
      "[0.44403785467147827, 0.7837413549423218]\n",
      "100/100 [==============================] - 0s 893us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79      1593\n",
      "           1       0.79      0.78      0.78      1593\n",
      "\n",
      "    accuracy                           0.78      3186\n",
      "   macro avg       0.78      0.78      0.78      3186\n",
      "weighted avg       0.78      0.78      0.78      3186\n",
      "\n",
      "[array([[ 1.60619393e-01, -4.44339961e-02,  1.45473611e-02,\n",
      "         2.07212567e-01,  3.04833919e-01,  3.37250647e-03,\n",
      "         2.21196190e-02, -5.43025613e-01, -4.92019430e-02,\n",
      "        -1.90014362e-01, -2.17581660e-01, -7.71949515e-02],\n",
      "       [ 8.69070515e-02,  1.12162074e-02, -2.52597839e-01,\n",
      "        -9.47064534e-02, -8.44723105e-01,  6.11442029e-02,\n",
      "        -1.09387441e-02,  1.24136448e-01,  1.04356324e-02,\n",
      "         1.48550019e-01,  1.05278738e-01,  1.75591230e-01],\n",
      "       [ 8.31163645e-01,  5.56927547e-02,  3.24259698e-01,\n",
      "        -1.78029394e+00,  4.05018955e-01,  4.87104833e-01,\n",
      "         1.48734856e+00, -1.36255205e+00,  1.47233498e+00,\n",
      "         8.53038847e-01,  1.09347963e+00,  9.85758305e-01],\n",
      "       [-9.46910586e-03, -1.20763183e-02,  2.30597541e-01,\n",
      "        -6.34649023e-02, -4.14552540e-01, -6.64334223e-02,\n",
      "        -7.42164999e-02,  3.83067518e-01,  3.32249589e-02,\n",
      "        -7.09130764e-02,  4.62341420e-02, -3.14835925e-03],\n",
      "       [-5.68728507e-01,  8.82246271e-02, -6.52676970e-02,\n",
      "        -3.04225504e-01, -5.20443320e-01, -1.10652256e+00,\n",
      "         8.46793950e-02, -2.12281756e-02,  2.74351239e-01,\n",
      "        -3.69230479e-01,  8.62617612e-01, -1.77984908e-01],\n",
      "       [-1.22631419e+00,  1.77042055e+00, -3.42603952e-01,\n",
      "         1.12734362e-01,  1.28613502e-01, -1.65408349e+00,\n",
      "        -5.50279796e-01, -3.87301058e-01,  2.63275445e-01,\n",
      "        -1.77556098e+00,  7.67230749e-01, -1.46504581e+00],\n",
      "       [-1.67665165e-02, -8.95985775e-03, -5.69838583e-01,\n",
      "         1.02490059e-03, -2.60515690e-01, -2.79620232e-04,\n",
      "         1.75895430e-02, -2.04057246e-01,  1.20807905e-02,\n",
      "        -5.84072359e-02, -5.82017824e-02,  8.01725220e-03],\n",
      "       [-7.06481159e-01, -1.29795605e-02, -3.79327267e-01,\n",
      "         4.97538075e-02,  3.24311525e-01, -7.18225092e-02,\n",
      "        -1.18251252e+00,  1.15545586e-01, -1.15039361e+00,\n",
      "         4.98665944e-02, -3.87596600e-02, -1.62542135e-01],\n",
      "       [ 1.28253773e-01,  8.39113258e-03, -1.23052824e+00,\n",
      "         1.53642118e-01, -1.98162183e-01, -1.58320777e-02,\n",
      "         7.46948970e-03, -3.75024199e-01,  4.33796123e-02,\n",
      "         1.47979617e-01,  1.65794846e-02, -6.13415986e-02],\n",
      "       [-6.33939207e-02, -1.48644447e-01, -2.71022588e-01,\n",
      "         1.52232513e-01,  3.54460865e-01,  8.09272304e-02,\n",
      "        -4.40303646e-02,  4.01347965e-01, -3.79412532e-01,\n",
      "         8.89261067e-02, -2.17397481e-01,  2.74016615e-02],\n",
      "       [-6.24054551e-01, -1.65841311e-01, -2.81294346e-01,\n",
      "         1.28884673e-01, -2.22626343e-01,  5.32436311e-01,\n",
      "         2.04936787e-02,  3.63058567e-01, -3.31582218e-01,\n",
      "         5.14054596e-01, -5.10105193e-01,  4.20711011e-01],\n",
      "       [ 1.55995702e-02, -1.18560098e-01,  3.25914621e-01,\n",
      "         1.09910749e-01, -2.18524039e-01,  1.07934631e-01,\n",
      "        -3.63156684e-02,  3.99994738e-02, -3.92742395e-01,\n",
      "        -4.78105098e-02, -2.05637306e-01,  5.65906316e-02]], dtype=float32), array([-1.73358217e-01, -5.07330179e-01, -6.20377585e-02,  3.10230881e-01,\n",
      "       -1.13863975e-01,  2.28300750e-01, -3.72463018e-01,  1.13204770e-01,\n",
      "       -1.47277683e-01,  2.10810656e-04, -3.63947213e-01,  9.56348777e-02],\n",
      "      dtype=float32), array([[-1.6644032 ,  0.7181918 ,  0.75995326, -1.5021183 ,  0.5385511 ,\n",
      "         0.6265499 ],\n",
      "       [-3.7624452 ,  1.6046691 ,  1.1741326 , -4.3998833 ,  0.26608112,\n",
      "         1.7583611 ],\n",
      "       [-0.6375738 ,  0.29245606,  0.18804853, -0.72893137, -0.27320847,\n",
      "        -0.5106256 ],\n",
      "       [ 0.6738033 , -0.84029406, -1.1844271 ,  0.31536373, -1.8600636 ,\n",
      "        -0.8035713 ],\n",
      "       [ 0.021231  , -1.0971997 , -0.09868801,  0.18634117,  0.18711777,\n",
      "        -1.2962368 ],\n",
      "       [-1.1334436 ,  0.04123389,  0.06527294, -2.709669  ,  0.3496776 ,\n",
      "         0.10762069],\n",
      "       [-0.85763204,  0.6119128 ,  1.1123273 , -2.0174258 , -0.08103456,\n",
      "         0.70833796],\n",
      "       [ 1.3913925 , -1.4890357 , -0.6793589 ,  1.4475471 , -1.2198719 ,\n",
      "        -1.2840341 ],\n",
      "       [-0.30807108,  0.79620004,  0.49087217, -1.086007  ,  0.48657334,\n",
      "         0.88126284],\n",
      "       [-0.66530126,  0.17986558,  0.4796422 , -1.2769048 ,  0.14990439,\n",
      "        -0.03306715],\n",
      "       [-0.76408917, -0.14880247,  0.22310904, -1.0485497 , -2.2756464 ,\n",
      "        -0.1328614 ],\n",
      "       [-0.50426227,  0.12907967, -0.50137913, -0.92803186,  0.27956232,\n",
      "         0.34102154]], dtype=float32), array([0.3425909 , 0.02252051, 0.00770389, 0.34221905, 0.01149597,\n",
      "       0.01027433], dtype=float32), array([[-1.5976276],\n",
      "       [ 1.2581197],\n",
      "       [ 1.2907847],\n",
      "       [-2.0746288],\n",
      "       [ 1.4065979],\n",
      "       [ 1.0819786]], dtype=float32), array([-0.2592397], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8b169297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8fb21179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regain Original features and labels\n",
    "X = df.drop('Exited',axis='columns')\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "69dade3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3aef9e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    6370\n",
       "1    1630\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ddd2b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = X_train.copy()\n",
    "df3['Exited'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1b2aa513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.554265</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339721</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>0.852</td>\n",
       "      <td>1</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.371163</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980432</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>0.664</td>\n",
       "      <td>1</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.325318</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>0.648</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.426077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8967</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts   \n",
       "5710        0.856       0  0.216216     0.5  0.554265       0.333333  \\\n",
       "3745        0.852       1  0.256757     0.1  0.371163       0.333333   \n",
       "5429        0.664       1  0.405405     0.7  0.000000       0.333333   \n",
       "551         0.648       0  0.391892     0.6  0.426077       0.000000   \n",
       "8967        0.970       0  0.094595     0.7  0.000000       0.333333   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_France   \n",
       "5710          0               0         0.339721                 1  \\\n",
       "3745          1               1         0.980432                 0   \n",
       "5429          1               0         0.325318                 1   \n",
       "551           1               1         0.010339                 0   \n",
       "8967          1               1         0.417230                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  Exited  \n",
       "5710                  0                0       0  \n",
       "3745                  1                0       0  \n",
       "5429                  0                0       0  \n",
       "551                   1                0       1  \n",
       "8967                  0                0       0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "003041d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_class0 = df3[df3.Exited==0]\n",
    "df3_class1 = df3[df3.Exited==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "61ed6d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6370, 13), (1630, 13))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_class0.shape, df3_class1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ec31d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "\n",
    "    X_train = df_train.drop('Exited', axis='columns')\n",
    "    y_train = df_train.Exited\n",
    "    return X_train, y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6577be8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.7025 - accuracy: 0.4706\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5316\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.5936\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6077\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6138\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6298\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6423\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.6515\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.6518\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6494\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6518\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6687\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6632\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6638\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6647\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6709\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.6819\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.6785\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.6721\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.6767\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.6877\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.6874\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.6828\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.6899\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.6883\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.6911\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.6985\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.6926\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.6945\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7028\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7025\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7049\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7018\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7089\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7166\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7104\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.6960\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7147\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7040\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7120\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7163\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7150\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7166\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7126\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7135\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7202\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7187\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7206\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7166\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7123\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7282\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7307\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7279\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7252\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7337\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7316\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7316\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7340\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7405\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7294\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7316\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7313\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7328\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7426\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7285\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7310\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7411\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7399\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7414\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7472\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7423\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7423\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7313\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7439\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7368\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7399\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7350\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7485\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7448\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7420\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7377\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7472\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7475\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7479\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7463\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7488\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7512\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7433\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7445\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7485\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7528\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7525\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7429\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7555\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7577\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7469\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7534\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7534\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7561\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7552\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7650\n",
      "[0.48602616786956787, 0.7649999856948853]\n",
      "63/63 [==============================] - 1s 1ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84      1593\n",
      "           1       0.45      0.77      0.57       407\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.69      0.77      0.70      2000\n",
      "weighted avg       0.83      0.77      0.78      2000\n",
      "\n",
      "[array([[-0.57968116,  0.02611097,  0.10238597, -0.28933355, -0.09673361,\n",
      "        -0.17050819, -0.19533087,  0.07249699, -0.06137744,  0.06929151,\n",
      "        -0.07024135,  0.18699339],\n",
      "       [-0.15392892,  0.04077575, -0.1770955 ,  0.03996528, -0.02552163,\n",
      "         0.04885393, -0.67527163, -0.23497851, -0.20675197, -0.2107875 ,\n",
      "         0.02569842, -0.15294966],\n",
      "       [-0.407235  ,  0.89486504, -1.0107274 ,  1.2443243 , -1.4855293 ,\n",
      "         0.7741969 , -0.76816475, -1.2986314 , -0.5443046 , -1.0427107 ,\n",
      "         0.21747588, -0.15414387],\n",
      "       [-0.05934681, -0.09734543,  0.11962126, -0.06783605, -0.10637152,\n",
      "         0.0744791 , -0.5220436 ,  0.09733448,  0.06704666,  0.2374057 ,\n",
      "         0.07284458, -0.3927125 ],\n",
      "       [-1.1331366 , -0.7034101 , -0.19339168,  0.1502021 ,  0.08207599,\n",
      "         0.56432265, -0.22687756, -0.2504776 , -0.18531682, -0.30828416,\n",
      "         0.06268231, -0.121847  ],\n",
      "       [ 0.49186847, -2.3522158 ,  1.1110218 , -0.41186094,  0.36533767,\n",
      "         1.2369192 , -0.14625862,  0.24841148, -0.08639257,  0.48965764,\n",
      "         2.073624  ,  0.27373028],\n",
      "       [ 0.23306361, -0.01819601,  0.03534498, -0.0770922 , -0.13062814,\n",
      "        -0.16488701, -0.29514354, -0.02751434,  0.20626155,  0.43642166,\n",
      "         0.0168132 , -0.06525564],\n",
      "       [-0.01312076, -0.20969729,  0.19081934, -0.09129345, -0.07312749,\n",
      "        -0.14468768, -0.6949936 ,  0.26541156, -0.2072848 ,  0.09807719,\n",
      "        -0.09817319,  0.527131  ],\n",
      "       [ 0.17772129, -0.02467063,  0.07049284,  0.07354624,  0.00313981,\n",
      "         0.00795942,  0.2553458 ,  0.03833661, -0.09522232, -0.04123875,\n",
      "         0.00914661,  0.18680206],\n",
      "       [-0.27087843,  0.09636036,  0.01924557,  0.02734389,  0.493815  ,\n",
      "        -0.21476014,  0.5332677 ,  0.00849133,  0.45368946, -0.137172  ,\n",
      "        -0.3862892 ,  0.03124043],\n",
      "       [ 0.08707537,  0.37049013, -0.2135149 ,  0.12538628,  0.39620638,\n",
      "        -0.36395127,  0.0770995 ,  0.11517179, -0.39315823, -0.32134312,\n",
      "        -0.36317092, -0.21984147],\n",
      "       [ 0.42749986,  0.13372466, -0.06721717,  0.08959003, -0.31679618,\n",
      "        -0.1885372 ,  0.6106326 ,  0.39007124,  0.0456219 , -0.3447325 ,\n",
      "        -0.31938744,  0.13280678]], dtype=float32), array([-0.21200995,  0.09795208,  0.25128895, -0.1584836 ,  0.23786667,\n",
      "       -0.3229443 ,  0.19023892,  0.11815979,  0.00628645,  0.08021343,\n",
      "       -0.4330642 ,  0.09092966], dtype=float32), array([[-0.01212817,  0.66388327, -0.76726806,  0.9382616 ,  0.73650396,\n",
      "        -0.166182  ],\n",
      "       [ 0.95575625, -0.88294   ,  0.47549543, -1.0437597 , -1.3522985 ,\n",
      "         1.0572389 ],\n",
      "       [ 0.07526296,  0.25851178, -0.8297725 ,  0.13065052,  0.58058673,\n",
      "         0.34208897],\n",
      "       [ 0.5935482 , -0.8966777 , -0.15322876, -1.1090977 , -0.6636874 ,\n",
      "        -0.15348208],\n",
      "       [-0.20728035,  0.13702983, -0.9855455 ,  0.36624706,  0.69921446,\n",
      "        -0.234895  ],\n",
      "       [ 0.71330416, -0.8647136 , -0.14598459, -0.8066683 , -0.9250645 ,\n",
      "         0.9419335 ],\n",
      "       [-0.99242043,  0.8961315 , -0.56551576,  1.4039873 ,  0.80999976,\n",
      "        -0.69977134],\n",
      "       [ 0.04381492,  0.30690303, -0.4968016 ,  0.48278946,  0.47933826,\n",
      "        -0.24583317],\n",
      "       [ 0.13038667,  0.07416146,  0.21269768,  0.2708811 ,  0.18990074,\n",
      "        -0.1311041 ],\n",
      "       [ 0.0574359 ,  0.67428184, -0.80370694,  0.6417555 ,  0.11267764,\n",
      "         0.15489835],\n",
      "       [ 1.2639544 , -1.1896391 ,  0.251429  , -0.9089038 , -1.1494254 ,\n",
      "         1.138324  ],\n",
      "       [-0.06936447,  0.08144294, -0.72078013,  0.07653947,  0.19616759,\n",
      "        -0.15085034]], dtype=float32), array([-0.05790602,  0.17192818,  0.40840793,  0.20483659,  0.08739369,\n",
      "       -0.19424972], dtype=float32), array([[ 0.90225947],\n",
      "       [-1.0412222 ],\n",
      "       [ 1.2357109 ],\n",
      "       [-0.8270379 ],\n",
      "       [-0.73095226],\n",
      "       [ 1.4304599 ]], dtype=float32), array([0.09806663], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df3_class0, df3_class1, 0, 1630)\n",
    "\n",
    "y_pred1 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3ff3bc10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5500\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.5939\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.6080\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.6276\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6405\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6485\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.6482\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6515\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.6537\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6613\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.6598\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6595\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6785\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6690\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6758\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.6847\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6926\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6859\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6972\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.7040\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7067\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7150\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.7123\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7147\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7288\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7242\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7196\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7258\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7273\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7291\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7380\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7310\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7294\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7273\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7248\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7365\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7429\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7331\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7285\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7411\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7387\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7433\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7359\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7368\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7442\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7245\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7359\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7276\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7380\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7350\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7414\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7350\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7362\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7451\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7325\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7359\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7393\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7405\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7454\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7445\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7429\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7420\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7466\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7417\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7365\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7469\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7497\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7442\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7472\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7429\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7365\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7506\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7485\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7426\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7417\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7632\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7433\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7503\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7574\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7515\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7420\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7491\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7534\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7497\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7506\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7472\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7469\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7546\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7475\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7509\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7534\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7506\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7546\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7512\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7506\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7491\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.8130\n",
      "[0.4581639766693115, 0.8130000233650208]\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88      1593\n",
      "           1       0.53      0.70      0.60       407\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.72      0.77      0.74      2000\n",
      "weighted avg       0.84      0.81      0.82      2000\n",
      "\n",
      "[array([[-2.74842054e-01,  1.13542199e-01,  2.30301723e-01,\n",
      "        -1.49938017e-01, -1.31861642e-01,  1.25110745e-01,\n",
      "        -2.52597660e-01,  3.96772623e-02,  1.25021234e-01,\n",
      "         4.43322882e-02, -8.68308768e-02,  7.72665674e-03],\n",
      "       [-2.77138082e-03,  7.66304284e-02, -9.23273340e-02,\n",
      "        -6.38693422e-02, -9.70939994e-02,  6.22025020e-02,\n",
      "         6.07181825e-02,  4.34873104e-02, -1.01909727e-01,\n",
      "        -1.00149801e-02,  4.40733042e-03,  1.99502259e-01],\n",
      "       [-3.37608345e-02,  4.33148863e-03, -1.05578315e+00,\n",
      "        -1.13392854e+00, -4.58105147e-01, -3.82236570e-01,\n",
      "         7.51805723e-01,  4.17428821e-01, -1.24257588e+00,\n",
      "         1.23915422e+00,  8.71653974e-01,  3.12568873e-01],\n",
      "       [-8.49222764e-02,  1.90335989e-01, -1.51754752e-01,\n",
      "         4.45191078e-02, -2.50662342e-02,  1.91110924e-01,\n",
      "        -2.64987107e-02, -3.06532048e-02,  4.40320633e-02,\n",
      "         3.15337516e-02, -1.76643893e-01, -9.95747223e-02],\n",
      "       [ 3.66592795e-01, -5.78233898e-01, -2.81521738e-01,\n",
      "        -9.17811543e-02, -5.08660436e-01,  1.15684353e-01,\n",
      "         1.83746412e-01, -7.06916392e-01,  1.60807669e-01,\n",
      "        -1.38503924e-01,  5.16625464e-01, -6.90424681e-01],\n",
      "       [ 1.61711359e+00, -5.47436118e-01,  1.88736111e-01,\n",
      "         1.71353832e-01, -3.07519555e-01,  1.37326443e+00,\n",
      "         1.25857711e+00, -1.68579841e+00,  5.29380858e-01,\n",
      "        -4.96036410e-01,  5.19793741e-02, -1.39984274e+00],\n",
      "       [-1.03911884e-01, -1.00786567e-01, -2.58841887e-02,\n",
      "         9.70161483e-02, -2.39951219e-02, -1.15695514e-03,\n",
      "        -1.23691365e-01, -3.17013450e-02, -9.82618928e-02,\n",
      "         2.71578487e-02,  1.06885023e-01, -1.79156050e-01],\n",
      "       [ 4.65345308e-02,  5.28622508e-01, -3.28563787e-02,\n",
      "         1.16467319e-01,  6.51260689e-02,  2.30324954e-01,\n",
      "        -2.12329283e-01, -8.52556080e-02,  1.90907959e-02,\n",
      "        -9.85146940e-01, -1.71091989e-01, -1.28918335e-01],\n",
      "       [ 3.73198316e-02, -2.35630929e-01,  9.66169238e-02,\n",
      "        -3.51356655e-01, -1.39736056e-01, -8.82370397e-02,\n",
      "         1.05007373e-01,  8.46048594e-02,  7.78030083e-02,\n",
      "         4.93463576e-02, -1.38138682e-01,  3.17840636e-01],\n",
      "       [ 1.55353947e-02,  1.40878260e-01,  2.37402946e-01,\n",
      "         4.86422390e-01,  5.45922637e-01, -8.45898315e-02,\n",
      "        -2.90395916e-01,  1.13404520e-01,  2.45152235e-01,\n",
      "        -3.11077565e-01, -7.18449578e-02,  2.20566750e-01],\n",
      "       [-1.29896834e-01, -2.89758861e-01,  2.24966601e-01,\n",
      "         1.81823522e-01, -4.84539866e-01, -4.55622077e-01,\n",
      "        -3.10272336e-01,  3.88747871e-01,  1.70351774e-01,\n",
      "        -2.90952682e-01,  2.50655022e-02,  5.69067180e-01],\n",
      "       [-9.60301608e-03,  1.19994491e-01, -3.98919106e-01,\n",
      "        -3.49171668e-01,  6.47210300e-01,  7.32368752e-02,\n",
      "        -2.83353955e-01,  1.32765204e-01,  2.29184076e-01,\n",
      "        -3.12757909e-01, -2.45723017e-02,  2.45043840e-02]], dtype=float32), array([-0.48732108, -0.08647081,  0.11997098,  0.01712229,  0.16294718,\n",
      "       -0.14030156, -0.22640577,  0.02626565,  0.09840648, -0.04439034,\n",
      "       -0.15007164,  0.04695988], dtype=float32), array([[ 1.5914586 ,  1.2450501 , -0.76308703,  1.3791231 ,  0.89746207,\n",
      "        -1.1744922 ],\n",
      "       [-0.24072471, -0.04985668,  0.10031633, -0.839935  , -0.5339671 ,\n",
      "         0.01921152],\n",
      "       [-0.7139863 , -0.44837576, -0.5806366 , -0.7378661 , -0.39386198,\n",
      "        -0.6646057 ],\n",
      "       [-0.8080587 , -0.5127324 , -0.40470204, -0.537291  , -0.13126425,\n",
      "        -0.07442647],\n",
      "       [-0.04300883, -0.05606799, -0.08591212, -0.756143  , -0.82412636,\n",
      "         0.37016216],\n",
      "       [-0.25444898, -0.2122282 , -0.44500726,  0.15544295,  0.3459857 ,\n",
      "        -0.4968489 ],\n",
      "       [ 0.0984359 , -0.2371142 ,  0.5235753 ,  0.84615755,  1.4190817 ,\n",
      "        -0.12941621],\n",
      "       [ 0.56233317,  0.57095355,  0.44707683, -0.09725935, -0.9125924 ,\n",
      "         0.5112914 ],\n",
      "       [-0.4770004 , -0.38812292, -0.57792646, -0.35165712,  0.2252742 ,\n",
      "        -1.0878756 ],\n",
      "       [ 0.6820319 ,  0.3902522 ,  1.1999133 ,  0.7513215 ,  0.5114558 ,\n",
      "         0.14788854],\n",
      "       [ 0.30485976,  0.16548815, -0.19737518,  0.4647192 ,  0.21630165,\n",
      "         0.04258007],\n",
      "       [ 0.32602552,  0.21514675, -0.13984172, -0.02811735, -0.8957095 ,\n",
      "         0.5872721 ]], dtype=float32), array([ 0.26027068,  0.18153068,  0.23921205,  0.2019273 , -0.19135395,\n",
      "        0.17724231], dtype=float32), array([[1.0193647],\n",
      "       [1.4110649],\n",
      "       [1.3516963],\n",
      "       [1.3969847],\n",
      "       [1.9603196],\n",
      "       [1.0211802]], dtype=float32), array([-1.3664376], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df3_class0, df3_class1, 1630, 3260)\n",
    "\n",
    "y_pred2 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2d62376c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5561\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5850\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.6101\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6202\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6233\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6313\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6472\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.6482\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.6485\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6466\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6521\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6564\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6699\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6684\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6764\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6730\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.6871\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.6877\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.6929\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.6954\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.6920\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.7049\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7150\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7074\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7224\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7212\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7184\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7245\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7294\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7242\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7218\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7307\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7196\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7239\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7356\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7331\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7334\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7414\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7383\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7387\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7285\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7426\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7436\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7319\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7371\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7472\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7426\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7414\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7451\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7390\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7537\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7433\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7374\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7423\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7525\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7488\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7457\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7479\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7546\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7494\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7515\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7506\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7571\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7506\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7531\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7583\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7690\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7552\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7525\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7537\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7567\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7595\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7592\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7580\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7561\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7540\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7567\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7571\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7586\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7546\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7604\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7666\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7552\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7583\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7650\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7638\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7623\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7644\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7638\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7626\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7669\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7696\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7681\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7635\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7574\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7623\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7675\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7586\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7604\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7575\n",
      "[0.4918668866157532, 0.7574999928474426]\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83      1593\n",
      "           1       0.45      0.78      0.57       407\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.69      0.76      0.70      2000\n",
      "weighted avg       0.83      0.76      0.78      2000\n",
      "\n",
      "[array([[-0.14652418,  0.04759673, -0.63422364, -0.3499578 , -0.00688544,\n",
      "        -0.12652497, -0.08220223,  0.30265665, -0.16124445, -0.09548866,\n",
      "        -0.1989516 , -0.43910024],\n",
      "       [ 0.00331404,  0.03660384,  0.33522585,  0.23689209, -0.13200629,\n",
      "        -0.08032224, -0.05764119, -0.23534271, -0.09551977, -0.17834061,\n",
      "         0.04821975,  0.11728051],\n",
      "       [ 0.1076094 ,  1.4830487 ,  0.41595635,  1.0478408 , -0.70635384,\n",
      "         0.41483504, -1.0864334 , -1.0209507 , -1.1386896 , -0.45338985,\n",
      "         0.7995226 ,  0.7513495 ],\n",
      "       [ 0.09659716, -0.03758515, -0.18067637,  0.07106663, -0.04528543,\n",
      "        -0.12459246,  0.00770349,  0.20288683, -0.18064098, -0.02394431,\n",
      "         0.02247597, -0.04076654],\n",
      "       [ 0.0552805 , -0.03676797, -0.46476948,  0.75937027, -0.15931614,\n",
      "         0.30294105, -0.01069052, -0.36429125, -0.27198187, -0.05048805,\n",
      "        -0.57688403, -0.17872056],\n",
      "       [ 1.1787152 , -0.7051471 , -0.6458158 ,  0.02588444,  0.41530713,\n",
      "         1.3701196 ,  0.33285618,  0.58826315,  0.4036239 ,  0.6788123 ,\n",
      "        -2.1709197 ,  0.92762864],\n",
      "       [ 0.00452735,  0.05856657, -0.06426647, -0.04218201,  0.07377072,\n",
      "         0.0378954 , -0.04362373,  0.13490316, -0.01449767, -0.01564773,\n",
      "         0.00346021, -0.05649106],\n",
      "       [-0.07621824, -1.0826509 , -0.2043322 , -0.16651766,  0.0825808 ,\n",
      "        -0.1031238 , -0.03226896,  0.26157042, -0.1097954 ,  0.34840468,\n",
      "        -0.07791354, -0.36829463],\n",
      "       [ 0.04100786, -0.02873731,  0.40285602, -0.05897113, -0.25828993,\n",
      "        -0.06289537, -0.11182266,  0.14423326, -0.00860852, -0.02969552,\n",
      "        -0.07945295, -0.05452654],\n",
      "       [-0.28702277, -0.14253217, -0.05759605, -0.20907927,  0.34579843,\n",
      "        -0.22588533,  0.41111457, -0.4596758 ,  0.4855586 ,  0.24655342,\n",
      "         0.12274772,  0.05076794],\n",
      "       [-0.33748072, -0.01391311, -0.09093332, -0.09601619,  0.15143906,\n",
      "        -0.3100302 ,  0.29140034, -0.27721503, -0.4212104 , -0.11286344,\n",
      "         0.3578687 ,  0.1220587 ],\n",
      "       [-0.2607598 , -0.12015578, -0.06812296, -0.19288209,  0.49744558,\n",
      "        -0.14264937, -0.5099662 , -0.15378079,  0.25803217, -0.04860483,\n",
      "         0.12274611, -0.05065519]], dtype=float32), array([-0.19907813, -0.23076898, -0.08060826, -0.21004306,  0.04446667,\n",
      "       -0.28784665,  0.1485062 ,  0.1074205 ,  0.18521164,  0.0475787 ,\n",
      "        0.06021645, -0.31471244], dtype=float32), array([[ 1.5291653 ,  1.183975  , -0.8052531 , -1.3431739 , -1.386517  ,\n",
      "         1.5575403 ],\n",
      "       [ 1.0693785 ,  0.9766022 , -0.54865444, -0.49366438, -0.7158975 ,\n",
      "         1.3565918 ],\n",
      "       [ 0.7483442 , -0.04151002,  0.12504995, -0.14455852, -0.19497819,\n",
      "         1.2645587 ],\n",
      "       [ 0.08328399, -0.14970018, -0.405437  , -0.7373185 , -0.4995249 ,\n",
      "         0.28104085],\n",
      "       [-0.5293992 , -0.02037006,  0.07732375,  0.10452129,  0.4550951 ,\n",
      "         0.01779202],\n",
      "       [ 0.5344987 ,  0.6733357 , -1.164303  , -1.3629985 , -0.8822482 ,\n",
      "         0.92264783],\n",
      "       [-0.5802081 ,  0.0512032 ,  0.19067916,  0.4105952 ,  0.1377203 ,\n",
      "        -0.33075428],\n",
      "       [-0.04502213,  0.01929445,  0.4778968 ,  0.47241938,  0.52909935,\n",
      "         0.03423095],\n",
      "       [-0.55898553,  0.02072727,  0.8014815 ,  0.4785198 ,  0.19296716,\n",
      "        -0.2511223 ],\n",
      "       [-0.14775966,  0.00410847,  0.05567047,  0.11799119,  0.14630911,\n",
      "         0.11305846],\n",
      "       [ 0.64960796, -0.53192693, -0.8316699 , -0.7690154 , -0.9973889 ,\n",
      "         0.92282915],\n",
      "       [ 0.9132332 ,  0.6370852 , -0.7550642 , -0.14968054, -0.16916348,\n",
      "         0.8127935 ]], dtype=float32), array([ 0.13186403, -0.04021614,  0.1116294 ,  0.18907945,  0.14162478,\n",
      "       -0.05729152], dtype=float32), array([[ 1.2536167],\n",
      "       [ 2.5209272],\n",
      "       [-1.4658407],\n",
      "       [-1.3266234],\n",
      "       [-1.2277069],\n",
      "       [ 1.0301015]], dtype=float32), array([0.07608664], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df3_class0, df3_class1, 3260, 4890)\n",
    "\n",
    "y_pred3 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9b97261d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000, 2000)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred1), len(y_pred2), len(y_pred3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7f113bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = y_pred1.copy()\n",
    "for i in range(len(y_pred1)):\n",
    "    n_ones = y_pred1[i] + y_pred2[i] + y_pred3[i]\n",
    "    if n_ones>1:\n",
    "        y_pred_final[i] = 1\n",
    "    else:\n",
    "        y_pred_final[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "30e10669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.78      0.85      1593\n",
      "           1       0.47      0.76      0.58       407\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.70      0.77      0.71      2000\n",
      "weighted avg       0.83      0.78      0.79      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_rep = classification_report(y_test, y_pred_final)\n",
    "print(cl_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CodeBas",
   "language": "python",
   "name": "codebas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
